{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0c558ea-7f5e-4b4d-a339-7a89e6778290",
   "metadata": {},
   "source": [
    "This jupyter gives you a simple example of how you should use the Simulated Network (asynchronous) environment. This environment is not meant as a training ground of your algorithms, but only to check whether or not your algorithm can be executed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92edcf65-93c1-4396-90d0-4572ec09c2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "\n",
    "# Add parent directory to path\n",
    "import sys\n",
    "from pathlib import Path\n",
    "current_dir = Path().resolve()\n",
    "root_dir = current_dir.parent\n",
    "if str(root_dir) not in sys.path:\n",
    "    sys.path.insert(0,str(root_dir))\n",
    "\n",
    "from Gyms.SimulatedNetwork import SimulatedNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7a528d5-af3f-4c5b-9bef-0fe0022a21cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define size of state and action spaces\n",
    "state_dim  = 4 # Dimension of reduced state space\n",
    "action_dim = 2 # Number of stimuli in action space (each stimulus needs a value of {0,1,2,3,4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5373dba-d31c-4f31-9906-6db506053bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current state: [0. 0. 0. 0.], Reward: 0\n"
     ]
    }
   ],
   "source": [
    "# Create environment and initialize it\n",
    "env      = SimulatedNetwork(action_dim=action_dim,state_dim=state_dim)\n",
    "state, _ = env.reset()\n",
    "env.render() # This function gives you the current state + reward, which both is 0 after initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5b3b3f7-8dc7-455f-bf05-df02d2ef95a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiDiscrete([5 5])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the action space dimensions\n",
    "env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c75680da-4bd1-40b1-a3fe-607e070a5c64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box(-1.0, 1.0, (4,), float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the state space dimensions\n",
    "env.observation_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7dc3ef6a-fb75-4834-b6e0-97826997584b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can now for example get a random action:\n",
    "action = env.action_space.sample()\n",
    "action\n",
    "# This action can then be applied to the environment with:\n",
    "# state, reward, terminated, truncated, info = env.step(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22ab4df5-8dc2-4e62-98f8-9fbda33eb750",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d5fdf0f-126b-49b9-bef0-79070d77b764",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.5       , -0.31019939,  0.        ,  0.        ]),\n",
       " 0,\n",
       " False,\n",
       " False,\n",
       " {'spikes': array([4.74396391, 7.14955549]),\n",
       "  'elecs': array([1, 2]),\n",
       "  'action': array([2, 0]),\n",
       "  'missed_cyc': 0,\n",
       "  'stim_id': 1,\n",
       "  'simulated': True,\n",
       "  'comment': 'none'})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.step(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1a4cc22-d672-490f-93c6-d98b3ca82de0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stimulate with action: [4 2]\n",
      "Reward: -1, Avg. reward: -1.0\n",
      "State: [0.5        0.         0.16133553 0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [4 4]\n",
      "Reward: 1, Avg. reward: 0.0\n",
      "State: [ 0.5         0.         -0.11049919  0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 0]\n",
      "Reward: 0, Avg. reward: 0.0\n",
      "State: [-0.5        -0.44381978  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [4 1]\n",
      "Reward: 1, Avg. reward: 0.25\n",
      "State: [ 0.5        -0.41625966  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [4 2]\n",
      "Reward: 1, Avg. reward: 0.4\n",
      "State: [ 0.5        -0.34176808 -0.16546339  0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 1]\n",
      "Reward: 2, Avg. reward: 0.6666666666666666\n",
      "State: [-0.5         0.37745128  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [0 0]\n",
      "Reward: 0, Avg. reward: 0.5714285714285714\n",
      "State: [0. 0. 0. 0.]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 0]\n",
      "Reward: 0, Avg. reward: 0.5\n",
      "State: [-1.         -0.46495632  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [3 0]\n",
      "Reward: 0, Avg. reward: 0.4444444444444444\n",
      "State: [ 0.         -0.43545606  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 4]\n",
      "Reward: 2, Avg. reward: 0.6\n",
      "State: [-0.5        -0.21636231 -0.07958416  0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [0 1]\n",
      "Reward: 0, Avg. reward: 0.5454545454545454\n",
      "State: [-1.         -0.28190593  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [0 3]\n",
      "Reward: 0, Avg. reward: 0.5\n",
      "State: [ 0.         -0.26390577  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [4 3]\n",
      "Reward: -1, Avg. reward: 0.38461538461538464\n",
      "State: [0.5        0.27533218 0.         0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [3 0]\n",
      "Reward: 0, Avg. reward: 0.35714285714285715\n",
      "State: [ 0.         -0.23497994  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [4 1]\n",
      "Reward: 1, Avg. reward: 0.4\n",
      "State: [ 0.5        -0.30156994  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 1]\n",
      "Reward: -1, Avg. reward: 0.3125\n",
      "State: [-0.5         0.36955477  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 3]\n",
      "Reward: 2, Avg. reward: 0.4117647058823529\n",
      "State: [-1.         -0.42378453 -0.15282605  0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 0]\n",
      "Reward: 0, Avg. reward: 0.3888888888888889\n",
      "State: [-1.         -0.32913228  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 3]\n",
      "Reward: 0, Avg. reward: 0.3684210526315789\n",
      "State: [-1.          0.07473278  0.37848417  0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [4 2]\n",
      "Reward: -1, Avg. reward: 0.3\n",
      "State: [-1.          0.32429027  0.22588106  0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 3]\n",
      "Reward: 1, Avg. reward: 0.3333333333333333\n",
      "State: [-0.5        -0.45481566  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 4]\n",
      "Reward: 1, Avg. reward: 0.36363636363636365\n",
      "State: [-0.5         0.          0.12076897  0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 2]\n",
      "Reward: -1, Avg. reward: 0.30434782608695654\n",
      "State: [-0.5        -0.32514193  0.15876737  0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 4]\n",
      "Reward: 0, Avg. reward: 0.2916666666666667\n",
      "State: [-1.        -0.2766739  0.         0.       ]\n",
      "-----------------------------\n",
      "Stimulate with action: [3 1]\n",
      "Reward: 2, Avg. reward: 0.36\n",
      "State: [0.5        0.16197613 0.         0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [3 2]\n",
      "Reward: -2, Avg. reward: 0.2692307692307692\n",
      "State: [0.5        0.21770708 0.38277419 0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 4]\n",
      "Reward: -1, Avg. reward: 0.2222222222222222\n",
      "State: [-1.          0.35025809  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 3]\n",
      "Reward: 1, Avg. reward: 0.25\n",
      "State: [-0.5         0.         -0.38695175  0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [3 2]\n",
      "Reward: 1, Avg. reward: 0.27586206896551724\n",
      "State: [ 0.         -0.36478776  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [3 2]\n",
      "Reward: 1, Avg. reward: 0.3\n",
      "State: [ 0.         -0.35680087  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [4 4]\n",
      "Reward: 1, Avg. reward: 0.3225806451612903\n",
      "State: [ 0.5         0.         -0.17513848  0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [4 0]\n",
      "Reward: 0, Avg. reward: 0.3125\n",
      "State: [ 0.5        -0.38863454  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 4]\n",
      "Reward: 0, Avg. reward: 0.30303030303030304\n",
      "State: [-0.5        -0.37065511 -0.13109714  0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [0 3]\n",
      "Reward: 0, Avg. reward: 0.29411764705882354\n",
      "State: [ 0.         -0.32275874  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 4]\n",
      "Reward: 1, Avg. reward: 0.3142857142857143\n",
      "State: [-1.         -0.41016134  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 3]\n",
      "Reward: 2, Avg. reward: 0.3611111111111111\n",
      "State: [0.5        0.         0.21250921 0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [3 2]\n",
      "Reward: -1, Avg. reward: 0.32432432432432434\n",
      "State: [0.         0.44419176 0.         0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 2]\n",
      "Reward: 0, Avg. reward: 0.3157894736842105\n",
      "State: [-1.         -0.42778375  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [4 2]\n",
      "Reward: -3, Avg. reward: 0.23076923076923078\n",
      "State: [0.5        0.         0.11437172 0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 1]\n",
      "Reward: 1, Avg. reward: 0.25\n",
      "State: [ 0.5       -0.1957644  0.         0.       ]\n",
      "-----------------------------\n",
      "Stimulate with action: [3 0]\n",
      "Reward: 0, Avg. reward: 0.24390243902439024\n",
      "State: [ 0.         -0.39397271  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [4 4]\n",
      "Reward: -1, Avg. reward: 0.21428571428571427\n",
      "State: [ 0.5        -0.35634643  0.18449461  0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 2]\n",
      "Reward: 1, Avg. reward: 0.23255813953488372\n",
      "State: [-1.         -0.31303632  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [0 2]\n",
      "Reward: 1, Avg. reward: 0.25\n",
      "State: [-0.5        -0.43033765 -0.29536555  0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 3]\n",
      "Reward: 0, Avg. reward: 0.24444444444444444\n",
      "State: [-1.         -0.48745292 -0.02665391  0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 0]\n",
      "Reward: 1, Avg. reward: 0.2608695652173913\n",
      "State: [-0.5        -0.32758757 -0.19289883  0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 4]\n",
      "Reward: -1, Avg. reward: 0.23404255319148937\n",
      "State: [-1.          0.35704687  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [3 4]\n",
      "Reward: 1, Avg. reward: 0.25\n",
      "State: [ 0.         -0.44660008  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [4 3]\n",
      "Reward: -1, Avg. reward: 0.22448979591836735\n",
      "State: [ 0.5        -0.29403533  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [3 4]\n",
      "Reward: -1, Avg. reward: 0.2\n",
      "State: [ 0.         -0.43975687  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [0 0]\n",
      "Reward: 0, Avg. reward: 0.19607843137254902\n",
      "State: [-0.5  0.   0.   0. ]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 0]\n",
      "Reward: 0, Avg. reward: 0.19230769230769232\n",
      "State: [-1.         -0.35761756  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [0 3]\n",
      "Reward: -1, Avg. reward: 0.16981132075471697\n",
      "State: [0.         0.         0.18672664 0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [3 3]\n",
      "Reward: 1, Avg. reward: 0.18518518518518517\n",
      "State: [0.5        0.26892902 0.         0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 3]\n",
      "Reward: 0, Avg. reward: 0.18181818181818182\n",
      "State: [-0.5         0.          0.27142031  0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [3 1]\n",
      "Reward: 2, Avg. reward: 0.21428571428571427\n",
      "State: [ 0.         -0.31081956 -0.0886041   0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [3 1]\n",
      "Reward: 0, Avg. reward: 0.21052631578947367\n",
      "State: [ 0.         -0.21750166 -0.30266127  0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 2]\n",
      "Reward: 1, Avg. reward: 0.22413793103448276\n",
      "State: [-1.         -0.41936543  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [3 1]\n",
      "Reward: 2, Avg. reward: 0.2542372881355932\n",
      "State: [ 0.         -0.29881314 -0.35184905  0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 0]\n",
      "Reward: -1, Avg. reward: 0.23333333333333334\n",
      "State: [-1.         -0.38139569  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [3 2]\n",
      "Reward: 2, Avg. reward: 0.26229508196721313\n",
      "State: [ 0.         -0.40408908  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [0 1]\n",
      "Reward: 1, Avg. reward: 0.27419354838709675\n",
      "State: [-1.          0.         -0.40468637  0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 3]\n",
      "Reward: -1, Avg. reward: 0.25396825396825395\n",
      "State: [-1.          0.          0.05180064  0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [0 3]\n",
      "Reward: 2, Avg. reward: 0.28125\n",
      "State: [ 0.5         0.31268759 -0.31140457  0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 0]\n",
      "Reward: 0, Avg. reward: 0.27692307692307694\n",
      "State: [-0.5        -0.45900474  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 3]\n",
      "Reward: 1, Avg. reward: 0.2878787878787879\n",
      "State: [-0.5        -0.36844289  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [3 1]\n",
      "Reward: 2, Avg. reward: 0.31343283582089554\n",
      "State: [ 0.         -0.4080316  -0.32434111  0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [0 0]\n",
      "Reward: 0, Avg. reward: 0.3088235294117647\n",
      "State: [-1.  0.  0.  0.]\n",
      "-----------------------------\n",
      "Stimulate with action: [0 0]\n",
      "Reward: 0, Avg. reward: 0.30434782608695654\n",
      "State: [0. 0. 0. 0.]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 0]\n",
      "Reward: 0, Avg. reward: 0.3\n",
      "State: [-1.         -0.39962999  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [4 3]\n",
      "Reward: 0, Avg. reward: 0.29577464788732394\n",
      "State: [ 0.5        -0.34940761  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 4]\n",
      "Reward: -1, Avg. reward: 0.2777777777777778\n",
      "State: [-1.          0.32611229  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [3 3]\n",
      "Reward: 1, Avg. reward: 0.2876712328767123\n",
      "State: [ 0.          0.         -0.26511468  0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [0 4]\n",
      "Reward: 1, Avg. reward: 0.2972972972972973\n",
      "State: [-1.          0.58050099 -0.26637649  0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 3]\n",
      "Reward: -1, Avg. reward: 0.28\n",
      "State: [-1.          0.          0.10934189  0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [0 2]\n",
      "Reward: -1, Avg. reward: 0.2631578947368421\n",
      "State: [-0.5  0.   0.   0. ]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 2]\n",
      "Reward: 1, Avg. reward: 0.2727272727272727\n",
      "State: [-1.         -0.42332455  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [3 0]\n",
      "Reward: 0, Avg. reward: 0.2692307692307692\n",
      "State: [ 0.         -0.37022599  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [4 1]\n",
      "Reward: 2, Avg. reward: 0.2911392405063291\n",
      "State: [ 0.5         0.         -0.13502182  0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 2]\n",
      "Reward: 2, Avg. reward: 0.3125\n",
      "State: [-0.5         0.         -0.09257629  0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 1]\n",
      "Reward: 2, Avg. reward: 0.3333333333333333\n",
      "State: [-1.          0.         -0.19724958  0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 3]\n",
      "Reward: 2, Avg. reward: 0.35365853658536583\n",
      "State: [ 0.5         0.         -0.38455151  0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 2]\n",
      "Reward: 1, Avg. reward: 0.3614457831325301\n",
      "State: [-1.         -0.42846715  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [4 2]\n",
      "Reward: 3, Avg. reward: 0.39285714285714285\n",
      "State: [ 0.         -0.28581826 -0.33827488  0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 3]\n",
      "Reward: 1, Avg. reward: 0.4\n",
      "State: [-0.5        -0.10693275  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 0]\n",
      "Reward: 0, Avg. reward: 0.3953488372093023\n",
      "State: [-1.         -0.28583254  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [4 0]\n",
      "Reward: 0, Avg. reward: 0.39080459770114945\n",
      "State: [ 0.5        -0.37757152  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [3 3]\n",
      "Reward: 1, Avg. reward: 0.3977272727272727\n",
      "State: [ 0.          0.         -0.20743763  0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [4 1]\n",
      "Reward: 1, Avg. reward: 0.4044943820224719\n",
      "State: [ 0.5        -0.42238257  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [0 0]\n",
      "Reward: 0, Avg. reward: 0.4\n",
      "State: [-1.  0.  0.  0.]\n",
      "-----------------------------\n",
      "Stimulate with action: [4 2]\n",
      "Reward: -1, Avg. reward: 0.38461538461538464\n",
      "State: [0.5        0.         0.23998479 0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 1]\n",
      "Reward: 0, Avg. reward: 0.3804347826086957\n",
      "State: [-1.         -0.46176999  0.25086478  0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [0 4]\n",
      "Reward: 0, Avg. reward: 0.3763440860215054\n",
      "State: [ 0.5        -0.32074422  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [0 0]\n",
      "Reward: 0, Avg. reward: 0.3723404255319149\n",
      "State: [0. 0. 0. 0.]\n",
      "-----------------------------\n",
      "Stimulate with action: [3 1]\n",
      "Reward: 0, Avg. reward: 0.3684210526315789\n",
      "State: [ 0.         -0.32685579 -0.17177312  0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 1]\n",
      "Reward: -1, Avg. reward: 0.3541666666666667\n",
      "State: [-0.5         0.35676513  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 0]\n",
      "Reward: 0, Avg. reward: 0.35051546391752575\n",
      "State: [-1.         -0.36287745  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 3]\n",
      "Reward: 1, Avg. reward: 0.35714285714285715\n",
      "State: [-0.5        -0.41938588  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 0]\n",
      "Reward: 0, Avg. reward: 0.35353535353535354\n",
      "State: [-1.         -0.41510856  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 0]\n",
      "Reward: 0, Avg. reward: 0.35\n",
      "State: [-1.         -0.35075063  0.          0.        ]\n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "# Example code, that stimulates the network 100 times with a randomly sampled action, while calculating also the average reward received\n",
    "\n",
    "total_reward = 0\n",
    "action_count = 0\n",
    "\n",
    "for _ in range(100):\n",
    "    # For simplicity, choose a random action\n",
    "    action = env.action_space.sample()\n",
    "    print(f\"Stimulate with action: {action}\")\n",
    "    \n",
    "    state, reward, terminated, truncated, info = env.step(action)\n",
    "    total_reward += reward\n",
    "    action_count += 1\n",
    "\n",
    "    print(f\"Reward: {reward}, Avg. reward: {total_reward/action_count}\")\n",
    "    print(f\"State: {state}\")\n",
    "\n",
    "    # If you want a more complete plotting of each step\n",
    "    # env.render()\n",
    "\n",
    "    print(\"-----------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e01d04d-21a2-4760-9f81-7bfe2884a916",
   "metadata": {},
   "outputs": [],
   "source": [
    "state, reward, terminated, truncated, info = env.step(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "08d6f566-df73-4654-8d63-72bded5f1fb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1.        ,  0.36726528, -0.11623551,  0.        ]), 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state,reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88227413-b0c8-42a3-be75-f3098e654f12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'spikes': array([2.09947933, 5.47157396, 5.80934131, 6.43806268]),\n",
       " 'elecs': array([0, 3, 0, 1]),\n",
       " 'action': array([1, 0]),\n",
       " 'missed_cyc': 0,\n",
       " 'stim_id': 102,\n",
       " 'simulated': True,\n",
       " 'comment': 'none'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9908809f-ad71-4ed0-9d67-9ce4eeaabe6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average reward: 0.35\n"
     ]
    }
   ],
   "source": [
    "print(f\"Average reward: {total_reward/action_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db20356d-4406-4b66-bd7d-9f6fb07b2292",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
